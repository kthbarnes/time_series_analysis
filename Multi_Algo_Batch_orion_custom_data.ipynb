{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using Orion for Custom Data\n",
        "\n",
        "This notebook is quick tutorial to use Orion on custom data.\n",
        "\n",
        "Before you start, please use GPU runtime for faster computation. From the top menu `Runtime -> Change runtime type -> T4 GPU`.\n",
        "\n",
        "## Step 0: install Orion on Colab\n",
        "Orion is available on pypi: https://pypi.org/project/orion-ml and can be installed directly via"
      ],
      "metadata": {
        "id": "ryw_yqg9JW9E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBt1rf72I1ex",
        "outputId": "cc72c598-1c67-4951-aba4-7948544e77e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: orion-ml in /usr/local/lib/python3.11/dist-packages (0.7.1)\n",
            "Requirement already satisfied: tensorflow<2.15,>=2.2 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (2.14.1)\n",
            "Requirement already satisfied: numpy<2,>=1.17.5 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (1.26.4)\n",
            "Requirement already satisfied: pandas<3,>=1 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (2.2.2)\n",
            "Requirement already satisfied: numba<0.60,>=0.48 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (0.59.1)\n",
            "Requirement already satisfied: s3fs<0.5,>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (0.4.2)\n",
            "Requirement already satisfied: mlblocks<0.7,>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (0.6.2)\n",
            "Requirement already satisfied: ml-stars<0.4,>=0.2.1.dev0 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (0.2.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=0.22.1 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (1.6.1)\n",
            "Requirement already satisfied: scipy<1.14 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (1.13.1)\n",
            "Requirement already satisfied: tabulate<0.9,>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (0.8.10)\n",
            "Requirement already satisfied: pyts<0.14,>=0.11 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (0.13.0)\n",
            "Requirement already satisfied: torch<2.6,>=1.4 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (2.5.1)\n",
            "Requirement already satisfied: azure-cognitiveservices-anomalydetector<0.4,>=0.3 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (0.3.1)\n",
            "Requirement already satisfied: xlsxwriter<1.4,>=1.3.6 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (1.3.9)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (4.67.1)\n",
            "Requirement already satisfied: stumpy<1.11,>=1.7 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (1.10.2)\n",
            "Requirement already satisfied: ncps in /usr/local/lib/python3.11/dist-packages (from orion-ml) (1.0.1)\n",
            "Requirement already satisfied: protobuf<4 in /usr/local/lib/python3.11/dist-packages (from orion-ml) (3.20.3)\n",
            "Requirement already satisfied: msrest>=0.6.21 in /usr/local/lib/python3.11/dist-packages (from azure-cognitiveservices-anomalydetector<0.4,>=0.3->orion-ml) (0.7.1)\n",
            "Requirement already satisfied: azure-common~=1.1 in /usr/local/lib/python3.11/dist-packages (from azure-cognitiveservices-anomalydetector<0.4,>=0.3->orion-ml) (1.1.28)\n",
            "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from azure-cognitiveservices-anomalydetector<0.4,>=0.3->orion-ml) (1.6.0)\n",
            "Requirement already satisfied: Keras<4,>=2.4 in /usr/local/lib/python3.11/dist-packages (from ml-stars<0.4,>=0.2.1.dev0->orion-ml) (2.14.0)\n",
            "Requirement already satisfied: statsmodels<0.15,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from ml-stars<0.4,>=0.2.1.dev0->orion-ml) (0.14.5)\n",
            "Requirement already satisfied: xgboost<2,>=0.72.1 in /usr/local/lib/python3.11/dist-packages (from ml-stars<0.4,>=0.2.1.dev0->orion-ml) (1.7.6)\n",
            "Requirement already satisfied: graphviz<1,>=0.9 in /usr/local/lib/python3.11/dist-packages (from mlblocks<0.7,>=0.6.2->orion-ml) (0.21)\n",
            "Requirement already satisfied: psutil<7,>=5 in /usr/local/lib/python3.11/dist-packages (from mlblocks<0.7,>=0.6.2->orion-ml) (5.9.5)\n",
            "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba<0.60,>=0.48->orion-ml) (0.42.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1->orion-ml) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1->orion-ml) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1->orion-ml) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from pyts<0.14,>=0.11->orion-ml) (1.5.1)\n",
            "Requirement already satisfied: botocore>=1.12.91 in /usr/local/lib/python3.11/dist-packages (from s3fs<0.5,>=0.2.2->orion-ml) (1.40.1)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from s3fs<0.5,>=0.2.2->orion-ml) (2025.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=0.22.1->orion-ml) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (3.14.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (25.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (4.14.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (1.74.0)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.15,>=2.2->orion-ml) (2.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=1.4->orion-ml) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.6,>=1.4->orion-ml) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ncps->orion-ml) (1.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.15,>=2.2->orion-ml) (0.45.1)\n",
            "Requirement already satisfied: azure-core>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-anomalydetector<0.4,>=0.3->orion-ml) (1.35.0)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from botocore>=1.12.91->s3fs<0.5,>=0.2.2->orion-ml) (1.0.1)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore>=1.12.91->s3fs<0.5,>=0.2.2->orion-ml) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-anomalydetector<0.4,>=0.3->orion-ml) (2025.7.14)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-anomalydetector<0.4,>=0.3->orion-ml) (0.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-anomalydetector<0.4,>=0.3->orion-ml) (2.0.0)\n",
            "Requirement already satisfied: requests~=2.16 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-anomalydetector<0.4,>=0.3->orion-ml) (2.32.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels<0.15,>=0.12.0->ml-stars<0.4,>=0.2.1.dev0->orion-ml) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.2->orion-ml) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.2->orion-ml) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.2->orion-ml) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.2->orion-ml) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.2->orion-ml) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.6,>=1.4->orion-ml) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.2->orion-ml) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.2->orion-ml) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.2->orion-ml) (4.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-anomalydetector<0.4,>=0.3->orion-ml) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-anomalydetector<0.4,>=0.3->orion-ml) (3.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-cognitiveservices-anomalydetector<0.4,>=0.3->orion-ml) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.2->orion-ml) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install orion-ml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries and Configure Paths\n",
        "import os\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"Configuring Orion paths...\")\n",
        "try:\n",
        "    import orion\n",
        "    import mlstars\n",
        "    from mlblocks import add_pipelines_path, add_primitives_path\n",
        "\n",
        "    # Get the installation directory for the mlstars and orion packages\n",
        "    mlstars_path = os.path.dirname(mlstars.__file__)\n",
        "    orion_path = os.path.dirname(orion.__file__)\n",
        "\n",
        "    # Add the dynamically found DIRECTORY paths for primitives and pipelines\n",
        "    add_primitives_path(os.path.join(mlstars_path, 'primitives'))\n",
        "    add_primitives_path(os.path.join(orion_path, 'primitives'))\n",
        "    add_pipelines_path(os.path.join(orion_path, 'pipelines'))\n",
        "\n",
        "    print(\"Orion paths configured successfully! ✅\")\n",
        "except ImportError as e:\n",
        "    print(f\"Error importing Orion libraries. Please ensure orion-ml is installed correctly: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during path configuration: {e}\")\n",
        "\n",
        "# Suppress FutureWarning messages for cleaner output\n",
        "# Else we will get a lot of warnings while runing the algos\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "print(\"Note: Warnings are being Ignored\")"
      ],
      "metadata": {
        "id": "cBwCVLVhPLZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6bee31a-5a45-4abb-b816-7705d8fe877e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuring Orion paths...\n",
            "Orion paths configured successfully! ✅\n",
            "Note: Warnings are being Ignored\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "try:\n",
        "    drive.mount('/content/gdrive')\n",
        "    #drive.mount('/content/gdrive', force_remount=True)\n",
        "    print(\"Google Drive mounted successfully. ✅\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}\")"
      ],
      "metadata": {
        "id": "i56OELrFrzWW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab207b4-e1fb-41b3-9286-b7b853e0a758"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/gdrive\n",
            "Google Drive mounted successfully. ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results will stored in the Anomaly_Results folder under a new file name with the structure \"timestamp_algorithm_name\""
      ],
      "metadata": {
        "id": "q7eVs4_3gI1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Configuration and Set Up Directories\n",
        "from datetime import datetime\n",
        "\n",
        "# --- Configuration ---\n",
        "INPUT_DATA_LOCATION = '/content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Datasets/'\n",
        "BASE_OUTPUT_LOCATION = '/content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/'\n",
        "\n",
        "# Generate a timestamped folder for the current session\n",
        "current_time = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "SESSION_FOLDER_NAME = f\"{current_time}_session\"\n",
        "SESSION_OUTPUT_LOCATION = os.path.join(BASE_OUTPUT_LOCATION, SESSION_FOLDER_NAME)\n",
        "\n",
        "# Create the main session directory\n",
        "try:\n",
        "    os.makedirs(SESSION_OUTPUT_LOCATION, exist_ok=True)\n",
        "    print(f\"Input data will be read from: {INPUT_DATA_LOCATION}\")\n",
        "    print(f\"All results for this session will be saved in: {SESSION_OUTPUT_LOCATION}\")\n",
        "except OSError as e:\n",
        "    print(f\"Error creating session directory: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5hiUSygi8JJ",
        "outputId": "72dd3576-9320-4987-bbc2-048cb3d44066"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data will be read from: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Datasets/\n",
            "All results for this session will be saved in: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Algorithm Pipelines and Hyperparameters\n",
        "\n",
        "# Interval set to 1 hour - we have timestamps of 15 minutes - 1 hour seems a good tradeoff\n",
        "# epoch value is set to 5 - since it runs on each csv file\n",
        "\n",
        "# some alogrithms need a lot more iterations - trail and error was used to get a suitable value\n",
        "# for e.g dense_autoencoder\n",
        "\n",
        "# only included verified pipelines\n",
        "\n",
        "pipelines = {\n",
        "    'aer': {\n",
        "        'mlstars.custom.timeseries_preprocessing.time_segments_aggregate#1': {\n",
        "            'interval': 3600\n",
        "        },\n",
        "        'orion.primitives.aer.AER#1': {\n",
        "            'epochs': 5,\n",
        "            'verbose': False\n",
        "        }\n",
        "    },\n",
        "    'tadgan': {\n",
        "        \"mlstars.custom.timeseries_preprocessing.time_segments_aggregate#1\": {\n",
        "            \"interval\": 3600\n",
        "        },\n",
        "        'orion.primitives.tadgan.TadGAN#1': {\n",
        "            'epochs': 5,\n",
        "            'verbose': False\n",
        "        }\n",
        "    },\n",
        "    'lstm_dynamic_threshold': {\n",
        "        \"mlstars.custom.timeseries_preprocessing.time_segments_aggregate#1\": {\n",
        "            \"interval\": 3600\n",
        "        },\n",
        "        'keras.Sequential.LSTMTimeSeriesRegressor#1': {\n",
        "            'epochs': 5,\n",
        "            'verbose': False\n",
        "        }\n",
        "    },\n",
        "    'lstm_autoencoder': {\n",
        "        \"mlstars.custom.timeseries_preprocessing.time_segments_aggregate#1\": {\n",
        "            \"interval\": 3600\n",
        "        },\n",
        "        'keras.Sequential.LSTMSeq2Seq#1': {\n",
        "            'epochs': 5,\n",
        "            'verbose': False\n",
        "        }\n",
        "    },\n",
        "    'dense_autoencoder': {\n",
        "        \"mlstars.custom.timeseries_preprocessing.time_segments_aggregate#1\": {\n",
        "            \"interval\": 3600\n",
        "        },\n",
        "        'keras.Sequential.DenseSeq2Seq#1': {\n",
        "            'epochs': 20,\n",
        "            'verbose': False\n",
        "        }\n",
        "    },\n",
        "    'vae': {\n",
        "        \"mlstars.custom.timeseries_preprocessing.time_segments_aggregate#1\": {\n",
        "            \"interval\": 3600\n",
        "        },\n",
        "        'orion.primitives.vae.VAE#1': {\n",
        "            'epochs': 5,\n",
        "            'verbose': False\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"Loaded configurations for {len(pipelines)} algorithms.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awbcLiMfgnYK",
        "outputId": "b4088af9-c323-4cdf-8a4f-ccffb33df352"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded configurations for 6 algorithms.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Main Processing Loop for All Algorithms and Files\n",
        "from orion import Orion\n",
        "\n",
        "# List to hold summary statistics from all algorithms\n",
        "all_algorithms_summary = []\n",
        "\n",
        "print(f\"\\nSearching for CSV files in '{INPUT_DATA_LOCATION}'...\")\n",
        "csv_files = glob.glob(os.path.join(INPUT_DATA_LOCATION, '*.csv'))\n",
        "\n",
        "if not csv_files:\n",
        "    print(\"No CSV files found in the specified directory.\")\n",
        "else:\n",
        "    print(f\"Found {len(csv_files)} CSV files. Starting processing...\\n\")\n",
        "\n",
        "# --- Main Algorithm Loop ---\n",
        "for algorithm_name, hyperparameters in pipelines.items():\n",
        "    print(f\"\\n{'='*20} Processing Algorithm: {algorithm_name.upper()} {'='*20}\")\n",
        "\n",
        "    # Create a subfolder for the current algorithm's results\n",
        "    ALGORITHM_OUTPUT_LOCATION = os.path.join(SESSION_OUTPUT_LOCATION, algorithm_name)\n",
        "    os.makedirs(ALGORITHM_OUTPUT_LOCATION, exist_ok=True)\n",
        "\n",
        "    # List to hold all detected anomalies for this algorithm\n",
        "    current_algorithm_anomalies = []\n",
        "\n",
        "    # --- File Processing Loop ---\n",
        "    for file_path in csv_files:\n",
        "        try:\n",
        "            dataset_name = os.path.basename(file_path)\n",
        "            print(f\"--- Processing: {dataset_name} ---\")\n",
        "\n",
        "            # 1. Load Data\n",
        "            data = pd.read_csv(file_path)\n",
        "\n",
        "            # 2. Format Data for Orion\n",
        "            data['timestamp_original'] = pd.to_datetime(data['timestamp'])\n",
        "            data['timestamp'] = data['timestamp_original'].values.astype(np.int64) // 10**9\n",
        "            if 'value' not in data.columns:\n",
        "                data.rename(columns={data.columns[1]: 'value'}, inplace=True)\n",
        "            orion_input_data = data[['timestamp', 'value']].copy()\n",
        "\n",
        "            # 3. Run Orion Anomaly Detection\n",
        "            print(f\"   - Running {algorithm_name} anomaly detection...\")\n",
        "            orion_detector = Orion(pipeline=algorithm_name, hyperparameters=hyperparameters)\n",
        "            detected_anomalies = orion_detector.fit_detect(orion_input_data)\n",
        "            print(f\"   - Detected {len(detected_anomalies)} anomaly interval(s).\")\n",
        "\n",
        "            # 4. Process and Augment Results\n",
        "            if not detected_anomalies.empty:\n",
        "                detected_anomalies['dataset_name'] = dataset_name\n",
        "                detected_anomalies['algorithm'] = algorithm_name\n",
        "                current_algorithm_anomalies.append(detected_anomalies)\n",
        "\n",
        "            data['is_anomaly'] = False\n",
        "            data['anomaly_severity'] = 0.0\n",
        "\n",
        "            for _, anomaly in detected_anomalies.iterrows():\n",
        "                anomaly_mask = (data['timestamp'] >= anomaly['start']) & (data['timestamp'] <= anomaly['end'])\n",
        "                data.loc[anomaly_mask, 'is_anomaly'] = True\n",
        "                current_severity = data.loc[anomaly_mask, 'anomaly_severity']\n",
        "                data.loc[anomaly_mask, 'anomaly_severity'] = np.maximum(current_severity, anomaly['severity'])\n",
        "\n",
        "            # 5. Save Augmented Data\n",
        "            augmented_filename = f\"{os.path.splitext(dataset_name)[0]}_augmented_{algorithm_name}.csv\"\n",
        "            augmented_filepath = os.path.join(ALGORITHM_OUTPUT_LOCATION, augmented_filename)\n",
        "            data.to_csv(augmented_filepath, index=False)\n",
        "            print(f\"   - Saved augmented data to: {augmented_filepath}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing {file_path} with {algorithm_name}: {e}\")\n",
        "\n",
        "    # --- Generate and Save Report for the Current Algorithm ---\n",
        "    if not current_algorithm_anomalies:\n",
        "        print(f\"\\nNo anomalies detected by {algorithm_name.upper()} in any dataset.\")\n",
        "        summary = {\n",
        "            'Algorithm': algorithm_name,\n",
        "            'Total Anomalies Detected': 0,\n",
        "            'Min Severity': 'N/A',\n",
        "            'Max Severity': 'N/A',\n",
        "            'Average Severity': 'N/A'\n",
        "        }\n",
        "    else:\n",
        "        consolidated_report = pd.concat(current_algorithm_anomalies, ignore_index=True)\n",
        "        consolidated_report['start_timestamp'] = pd.to_datetime(consolidated_report['start'], unit='s')\n",
        "        consolidated_report['end_timestamp'] = pd.to_datetime(consolidated_report['end'], unit='s')\n",
        "\n",
        "        report_filename = f\"{algorithm_name}_consolidated_report.csv\"\n",
        "        report_filepath = os.path.join(ALGORITHM_OUTPUT_LOCATION, report_filename)\n",
        "        consolidated_report.to_csv(report_filepath, index=False)\n",
        "        print(f\"\\nConsolidated report for {algorithm_name.upper()} saved to: {report_filepath}\")\n",
        "\n",
        "        # Collect stats for the final summary report\n",
        "        summary = {\n",
        "            'Algorithm': algorithm_name,\n",
        "            'Total Anomalies Detected': len(consolidated_report),\n",
        "            'Min Severity': consolidated_report['severity'].min(),\n",
        "            'Max Severity': consolidated_report['severity'].max(),\n",
        "            'Average Severity': consolidated_report['severity'].mean()\n",
        "        }\n",
        "    all_algorithms_summary.append(summary)\n",
        "\n",
        "print(\"\\n\\n--- All files and algorithms processed. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdEQh1dYiAEC",
        "outputId": "20f694db-0b8e-4e22-97ff-e789bfe33cfc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for CSV files in '/content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Datasets/'...\n",
            "Found 2 CSV files. Starting processing...\n",
            "\n",
            "\n",
            "==================== Processing Algorithm: AER ====================\n",
            "--- Processing: cs_inbound_AT03.csv ---\n",
            "   - Running aer anomaly detection...\n",
            "68/68 [==============================] - 2s 19ms/step\n",
            "68/68 [==============================] - 4s 41ms/step\n",
            "   - Detected 2 anomaly interval(s).\n",
            "   - Saved augmented data to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/aer/cs_inbound_AT03_augmented_aer.csv\n",
            "--- Processing: cs_inbound_AT01.csv ---\n",
            "   - Running aer anomaly detection...\n",
            "68/68 [==============================] - 3s 34ms/step\n",
            "68/68 [==============================] - 3s 27ms/step\n",
            "   - Detected 1 anomaly interval(s).\n",
            "   - Saved augmented data to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/aer/cs_inbound_AT01_augmented_aer.csv\n",
            "\n",
            "Consolidated report for AER saved to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/aer/aer_consolidated_report.csv\n",
            "\n",
            "==================== Processing Algorithm: TADGAN ====================\n",
            "--- Processing: cs_inbound_AT03.csv ---\n",
            "   - Running tadgan anomaly detection...\n",
            "68/68 [==============================] - 7s 88ms/step\n",
            "68/68 [==============================] - 8s 110ms/step\n",
            "68/68 [==============================] - 2s 26ms/step\n",
            "   - Detected 3 anomaly interval(s).\n",
            "   - Saved augmented data to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/tadgan/cs_inbound_AT03_augmented_tadgan.csv\n",
            "--- Processing: cs_inbound_AT01.csv ---\n",
            "   - Running tadgan anomaly detection...\n",
            "68/68 [==============================] - 8s 99ms/step\n",
            "68/68 [==============================] - 9s 119ms/step\n",
            "68/68 [==============================] - 1s 20ms/step\n",
            "   - Detected 2 anomaly interval(s).\n",
            "   - Saved augmented data to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/tadgan/cs_inbound_AT01_augmented_tadgan.csv\n",
            "\n",
            "Consolidated report for TADGAN saved to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/tadgan/tadgan_consolidated_report.csv\n",
            "\n",
            "==================== Processing Algorithm: LSTM_DYNAMIC_THRESHOLD ====================\n",
            "--- Processing: cs_inbound_AT03.csv ---\n",
            "   - Running lstm_dynamic_threshold anomaly detection...\n",
            "   - Detected 2 anomaly interval(s).\n",
            "   - Saved augmented data to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/lstm_dynamic_threshold/cs_inbound_AT03_augmented_lstm_dynamic_threshold.csv\n",
            "--- Processing: cs_inbound_AT01.csv ---\n",
            "   - Running lstm_dynamic_threshold anomaly detection...\n",
            "   - Detected 2 anomaly interval(s).\n",
            "   - Saved augmented data to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/lstm_dynamic_threshold/cs_inbound_AT01_augmented_lstm_dynamic_threshold.csv\n",
            "\n",
            "Consolidated report for LSTM_DYNAMIC_THRESHOLD saved to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/lstm_dynamic_threshold/lstm_dynamic_threshold_consolidated_report.csv\n",
            "\n",
            "==================== Processing Algorithm: LSTM_AUTOENCODER ====================\n",
            "--- Processing: cs_inbound_AT03.csv ---\n",
            "   - Running lstm_autoencoder anomaly detection...\n",
            "   - Detected 2 anomaly interval(s).\n",
            "   - Saved augmented data to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/lstm_autoencoder/cs_inbound_AT03_augmented_lstm_autoencoder.csv\n",
            "--- Processing: cs_inbound_AT01.csv ---\n",
            "   - Running lstm_autoencoder anomaly detection...\n",
            "   - Detected 2 anomaly interval(s).\n",
            "   - Saved augmented data to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/lstm_autoencoder/cs_inbound_AT01_augmented_lstm_autoencoder.csv\n",
            "\n",
            "Consolidated report for LSTM_AUTOENCODER saved to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/lstm_autoencoder/lstm_autoencoder_consolidated_report.csv\n",
            "\n",
            "==================== Processing Algorithm: DENSE_AUTOENCODER ====================\n",
            "--- Processing: cs_inbound_AT03.csv ---\n",
            "   - Running dense_autoencoder anomaly detection...\n",
            "   - Detected 2 anomaly interval(s).\n",
            "   - Saved augmented data to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/dense_autoencoder/cs_inbound_AT03_augmented_dense_autoencoder.csv\n",
            "--- Processing: cs_inbound_AT01.csv ---\n",
            "   - Running dense_autoencoder anomaly detection...\n",
            "   - Detected 2 anomaly interval(s).\n",
            "   - Saved augmented data to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/dense_autoencoder/cs_inbound_AT01_augmented_dense_autoencoder.csv\n",
            "\n",
            "Consolidated report for DENSE_AUTOENCODER saved to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/dense_autoencoder/dense_autoencoder_consolidated_report.csv\n",
            "\n",
            "==================== Processing Algorithm: VAE ====================\n",
            "--- Processing: cs_inbound_AT03.csv ---\n",
            "   - Running vae anomaly detection...\n",
            "68/68 [==============================] - 5s 58ms/step\n",
            "   - Detected 3 anomaly interval(s).\n",
            "   - Saved augmented data to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/vae/cs_inbound_AT03_augmented_vae.csv\n",
            "--- Processing: cs_inbound_AT01.csv ---\n",
            "   - Running vae anomaly detection...\n",
            "68/68 [==============================] - 5s 65ms/step\n",
            "   - Detected 2 anomaly interval(s).\n",
            "   - Saved augmented data to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/vae/cs_inbound_AT01_augmented_vae.csv\n",
            "\n",
            "Consolidated report for VAE saved to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/vae/vae_consolidated_report.csv\n",
            "\n",
            "\n",
            "--- All files and algorithms processed. ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and Save Final Summary Report\n",
        "\n",
        "if not all_algorithms_summary:\n",
        "    print(\"\\nNo summary data was generated.\")\n",
        "else:\n",
        "    # Create a DataFrame from the summary list\n",
        "    summary_df = pd.DataFrame(all_algorithms_summary)\n",
        "    summary_df = summary_df.set_index('Algorithm')\n",
        "\n",
        "    # --- Console Output Summary ---\n",
        "    print(\"\\n\\n--- Overall Algorithm Performance Summary ---\")\n",
        "    # CORRECTED LINE: Provide a callable function to the float_format parameter\n",
        "    print(summary_df.to_string(float_format='{:.4f}'.format))\n",
        "\n",
        "    # --- Save Final Summary CSV Report ---\n",
        "    summary_filename = f\"{SESSION_FOLDER_NAME}_overall_summary.csv\"\n",
        "    summary_filepath = os.path.join(SESSION_OUTPUT_LOCATION, summary_filename)\n",
        "\n",
        "    try:\n",
        "        summary_df.to_csv(summary_filepath)\n",
        "        print(f\"\\nFinal summary report saved to: {summary_filepath} ✅\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError saving final summary report: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE0SwWJwt5Ey",
        "outputId": "ae3e2874-6210-4118-c618-b5187dbd970e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- Overall Algorithm Performance Summary ---\n",
            "                        Total Anomalies Detected  Min Severity  Max Severity  Average Severity\n",
            "Algorithm                                                                                     \n",
            "aer                                            3        0.1828        0.8048            0.3959\n",
            "tadgan                                         5        0.1176        1.9696            0.6501\n",
            "lstm_dynamic_threshold                         4        0.6484        0.8491            0.7253\n",
            "lstm_autoencoder                               4        0.1809        2.2494            0.8008\n",
            "dense_autoencoder                              4        0.0233        2.0317            0.6654\n",
            "vae                                            5        0.2007        2.1995            0.8415\n",
            "\n",
            "Final summary report saved to: /content/gdrive/MyDrive/Colab Notebooks/Traffic analysis/Anomaly_Results/20250802_180212_session/20250802_180212_session_overall_summary.csv ✅\n"
          ]
        }
      ]
    }
  ]
}